%%%% -*- Mode: LaTeX -*-
%%
%% This is the draft of the 2nd part of EXPRESS/SOS 2018 paper, co-authored by
%% Prof. Davide Sangiorgi and Chun Tian.

\subsection{CCS, Transitions and Bisimilarities}

In the formalization of CCS, it's better to have two distinct
types for actions: the type \HOLty{:'b Label} ($\beta$ is a type variable.) for visible actions, divided by input
and output actions:
\begin{lstlisting}
val _ = Datatype `Label = name 'b | coname 'b`;
\end{lstlisting}
and the type \HOLty{:'b Action} as the
union of all visible and invisible actions. The cardinality of all
available types depends on the choice of type variable $\beta$.

The core datatype ``\HOLty{:('a, 'b) CCS}'' is then defined as an inductive
datatype in HOL, based on its Datatype package:
\begin{lstlisting}
val _ = Datatype `CCS = nil
		      | var 'a
		      | prefix ('b Action) CCS
		      | sum CCS CCS
		      | par CCS CCS
		      | restr (('b Label) set) CCS
		      | relab CCS ('b Relabeling)
		      | rec 'a CCS`;
\end{lstlisting}

We have added some minimal grammar support using HOL's powerful pretty printer, to represent CCS
processes in more readable forms. Table \ref{tab:ccsoperator} has listed the notation of typical CCS processes and
major operators supported by above definition. (Notice the use of
recursition operator for representing process constants)
\begin{table}[h]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Operator} & \textbf{Notation} & \textbf{HOL} & \textbf{HOL
  (alternative)}\\
\hline
nil & $\textbf{0}$ &  \HOLtm{nil} & \HOLtm{nil} \\
Rrefix & $a.b.0$ & \texttt{prefix a (prefix b nil)} & \HOLtm{prefix a
                                                     (prefix b nil)} \\
Sum & $p + q$ & \texttt{sum p q} & \HOLtm{sum p q} \\
Parallel & $p \,\mid\, q$ & \texttt{par p q} & \HOLtm{p || q} \\
Restriction & $(\nu\;L)\;p$ & \texttt{restr L p} & \HOLtm{restr L p} \\
Constant & $A=a.A$ & \texttt{rec A (prefix a (var A))} & \HOLtm{rec A
                                                        (prefix a (var
                                                        A))} \\
\hline
\end{tabular}
\end{center}
   \caption{Syntax of CCS operators}
   \label{tab:ccsoperator}
\end{table}

The transition semantics of CCS processes were defined by the following
Structural Operational Semantics (SOS for short) rules in
Fig.\;\ref{f:LTSCCS}, except that the transition rule for constants
has been changed to recursion operator:
\begin{alltt}
\HOLthm{CCS.REC}
\end{alltt}
which says, if we substitute all appearences of constant $X$ in $E$ to
$(\mathbf{rec}\; X\; E)$ and the resulting process has a transition to $E_1$
with action $u$, then $(\mathbf{rec}\; X\; E)$ has the same
transition.

\subsection{Coarsest (pre)congruence contained in $\approx$ (or $\succeq_{\mathrm{bis}}$)}

The ``coarsest congruence contained in weak bisimilarity ($\approx$)''
theorem in CCS is somehow special, as its current known proofs either
rely on quite restricted conditions, or have an extremely complicated proof
(c.f. van Glabbek's paper) in
which ordinal theory is required.  Actually even the relationship
between its name and statement is not well explained in many CCS
textbooks. But van Glabbek's paper has given the so far clearest
explainion, here we briefly repeat his arguments:

As we know weak bisimilarity ($\approx$) is not (real) congruence, as
it doesn't satisfy subsitutivity on direct sums (but if the CCS syntax
is non-standard, i.e. has only prefixed sums, $\approx$ is indeed a
congruence). The purpose is to find a coarsest congruence contained in
weak bisimilarity. (``coarsest'' means, any other congruence finer than it must be contained in it)
There're two ways to build a congruence from weak bisimilarity, one
way is the standard definition for observational congruence (rooted
weak bisimilarity) $\approx^c$ in CCS textbooks, but even it's proven to be a
congruence we don't know if it's coarsest one.  The other way is to
build a (pre)congruence closure (Def ??) directly upon
the original weak bisimilarity relation, we call the resulting
relation ``Weak bisimilarity congruence'' ($[\approx]$):
\begin{alltt}
\HOLthm[def]{CoarsestCongr.WEAK_CONGR}
\HOLthm[def]{Congruence.CC_def}
\end{alltt}
It can be shown that any such (pre)congruence closure is automatically coarset.

Now it remains to prove that, the congrunce relation built by above
two quite different approaches actually coincide. To achive this goal,
we first noticed that, all other operators beside sums used in
semantic context doesn't matter, because they're already substituible
for weak bisimilarity. The only important operator is the sum
operator. To focus on this important operator, we can temporily
introduce another concept called \emph{sum equivalence}:
\begin{alltt}
\HOLthm[def]{CoarsestCongr.SUM_EQUIV}
\end{alltt}
It can be shown that, weak bisimilarity congruence implies this sum
equivalence. Thus if we can further prove that the sum
equivalence imples observational congrence, all the three relations
must coincide together, as shown in the following diagram:
\begin{displaymath}
\xymatrix{
{\textrm{Weak bisimilarity } (\approx)} & {\textrm{Sum
    equivalence } (\approx^+)} \ar@/^3ex/[ldd]^{\subseteq ?}\\
{\textrm{Weak bisim. congruence } ([\approx])}
\ar[u]^{\subseteq} \ar[ru]^{\subseteq} \\
{\textrm{Rooted bisimilarity } (\approx^c)} \ar[u]^{\subseteq}
}
\end{displaymath}
In another words, observational congruence is the coarsest congruence
contained in weak bisimilary if and only if
\begin{equation}
\forall p\; q.\; p \approx^c\! q \Longleftrightarrow \forall r.\; p+r \approx
q+r
\end{equation}

The classical assumption for proving above theorem requires that $p$
and $q$ do not use up all available visible actions,
i.e. $\mathrm{fn}(p) \cup \mathrm{fn}(q) \neq \mathscr{L}$. But it's
not easy to formalize and use such an assumption without a detailed
treatment on free and bound names (visible actions) of CCS
processes.\footnote{There're totally four such concepts: 1) free names
are all visible actions appearing in a CCS term without surrounding
$\nu$ (restriction) operator on the same action; 2) bound names are
the set of all actions ever used by $\nu$ (restriction) operator; 3)
free variables (or equation variables) are those variables without a
definition given by recursion
operator; 4) bound variables (process constants) are variables with
definitions given by recursion operator. All CCS results using these
concepts are not touched so far, although these four concepts are
successfully defined using HOL's set and list theories.} However, by
analyzing the proof steps, we found that, what's really required is to
not use up all available labels in those weak transitions directly
lead from $p$ and $q$. In another words, even they have used all
available labels, as long as their first weak transitions didn't, the
whole proof can still be finished.\footnote{Further more, $p$ and $q$
  can be considered separately: the proof can be finished as long as
  \emph{each} of them didn't use up all labels on first weak
  transition, while the union of these labels are all labels.}
We have formalized this property of
CCS process and call it ``free action'' property:
\begin{alltt}
\HOLthm{CoarsestCongr.free_action_def}
\end{alltt}
With this property, the classical form of this theorem that we have
formally proved is:
\begin{alltt}
\HOLthm{CoarsestCongr.COARSEST_CONGR_THM}
\end{alltt}

If we drop this classical assumption, then the proof becomes much
harder, as given a van Glabbek's paper. The most important
intermediate result we have proved here, is the following lemma:
\begin{alltt}
\HOLthm{CoarsestCongr.PROP3_COMMON}
\end{alltt}
It roughly says, for any two processes $p$ and $q$, if we can find
another stable (no $\tau$-transitions) process $k$ which is not weak bisimilar to any transition of
$p$ and $q$, then the hard part of our main theorem is proved. In
practice, once two processes were given, it's not hard to find
such a process, but the arbitrariness of $p$ and $q$ made this result
extremely hard to prove. The method given by van Glabbek requires a
construction of arbitrarily non-bisimilar processes called ``Klop
processes'':
\begin{definition}{(Klop processes)}
For each ordinal $\lambda$, and an arbitrary chosen non-$\tau$ action $a$,
define a CCS process $k_\lambda$ as follows:
\begin{enumerate}
\item $k_0 = 0$,
\item $k_{\lambda+1} = k_\lambda + a.k_\lambda$ and
\item for $\lambda$ a limit ordinal, $k_\lambda = \sum_{\mu < \lambda}
  k_\mu$, meaning that $k_\lambda$ is constructed from all graphs
  $k_\mu$ for $\mu < \lambda$ by identifying their root.
\end{enumerate}
\end{definition}
It's not hard to prove that, all $k_i$ are non-bisimilar (not only
weakly but also strongly). The idea is, for any two processes, the union of sets of their all
transitions cannot be arbitrarily large: it has to be limited by an
ordinal number. But above contruction can be arbitrarily large, so
there always exists a Klop process which can be used to satisfy above
lemma (and finish the proof).

However, this goes beyond HOL's expressivity to define above process, mostly
because there's no way to express infinite ``sums'' in CCS
datatype.\footnote{There're actually several ways to modify the
  datatype to support infinite sums, but none of these infinity can be
arbitrary. The full version of ordinal theory cannot be expressed in HOL.}
What we can do is to eliminate the last branch with limiting
ordinals, and define Klop processes only on finite cases:
\begin{alltt}
\HOLthm[def]{CoarsestCongr.KLOP_def}\hfill[KLOP_def]
\end{alltt}
But this means we much assume the two processes $p$ and $q$ are
finite-state, i.e. their corresponding LTS graphs have only finite
states. Choosing an element from a countable infinite set of processes
to make sure it's not bisimiar with a given set of processes, this is
essentially a pure set-theoretic problem, as formalized and proved in
the following lemma:
\begin{alltt}
\HOLthm{CoarsestCongr.INFINITE_EXISTS_LEMMA}
\end{alltt}

With all these results, finally we can prove the ``coarsest congruence
contained in $\approx$'' theorem for finite-state CCS:
\begin{alltt}
\HOLthm{CoarsestCongr.COARSEST_CONGR_FINITE}
\end{alltt}

For contraction and rooted contraction, the situation (and proof
steps) is exactly the same:
\begin{displaymath}
\xymatrix{
{\textrm{Contraction } (\succeq_{\mathrm{bis}})} & {\textrm{Sum
    contraction } (\succeq_{\mathrm{bis}}^+)} \ar@/^3ex/[ldd]^{\subseteq ?}\\
{\textrm{Contraction precongruence } ([\succeq_{\mathrm{bis}}])}
\ar[u]^{\subseteq} \ar[ru]^{\subseteq} \\
{\textrm{Rooted contraction } (\succeq_{\mathrm{bis}}^c)} \ar[u]^{\subseteq}
}
\end{displaymath}

And we got two versions of theorem saying rooted contraction is the
coarsest precongruence of (bisimilarity) contraction:
\begin{alltt}
\HOLthm{Contraction.COARSEST_PRECONGR_THM'}
\HOLthm{Contraction.COARSEST_PRECONGR_FINITE}
\end{alltt}

\subsection{Semantic context, guardness and (pre)congruence}

We need to find a suitable formal definition of semantic
context. There're multiple ways. Here we have chosen to use $\lambda$-expressions (typed
$CCS\rightarrow CCS$) to represent a (multi-hole) semantic
context. The definition is inductive:
\begin{alltt}
\HOLthm[def]{Congruence.CONTEXT_rules}
\end{alltt}

Under above definition, we can formally define the concept of
``precongruence'' and ``congruence'' in the following ways:
\begin{alltt}
\HOLthm[def]{Congruence.precongruence_def}
\HOLthm[def]{Congruence.congruence_def}
\end{alltt}

A \emph{weak guarded} context is a context in which all holes appears
in the sub-expression of prefixed processes. We can easily define it
following the same idea:
\begin{alltt}
\HOLthm[def]{Congruence.WG_rules}
\end{alltt}
(Notice the differences between a weak guarded context and a normal
one: $\lambda t. t$ is not weakly guarded as the variable is directly
exposed without any prefixed action. And $\lambda t. a.e[t]$ is weakly
guarded as long as $e[\cdot]$ is a semantic context, no necessary weakly guaded.)

It's a similar process to define strongly guarded context
(\texttt{SG}), sequential context (\texttt{SEQ}) and their
variants without direct sums (\texttt{GCONTEXT}, \texttt{WGS},
\texttt{GSEQ}). Some lemmas about their relationships have very long
(but trivial) formal proofs due to the combinatorial explosion of
inductions on their structures. For example, one such 
lemma says, for any semantic context $E$ which is both strongly guarded
and sequential (no direct sums) and another sequential context $H$ (no
direct sums), the composition $H \circ E$ is still both strongly
guarded and sequential (no direct sums):
\begin{alltt}
SG_GSEQ_combin:
\HOLthm{Congruence.SG_GSEQ_combin}
\end{alltt}

\subsection{Milner's ``unique solution of equations'' theorems}

Once the representation issue of CCS equations is resolved, the actual
proofs of Milner's unique solution of equations theorems is not very
interesting from the view of theorem proving, although it's a 
precise proof engineering work producing quite long proofs.
Since we have chosen to use semantic context to represent
single-variable equations, an equation like $P \sim E\{P/X\}$ now
becomes $P \sim E[P]$, in which $E$ is a (multi-hole) semantic
context, and there's no need to say it ``contains at most the variable
$X$'' any more, as equation variable doesn't appear in $E$ at
all. Under these simplifications, the formal proof of Milner's unique
solution of equations theorem for $\sim$ is a literal mapping for informal
proofs based on bisimulation upto $\sim$, induction and case analysis
of weakly guarded contexts. Below is the formal version of Lemma 4.13
and Proposition 4.14 in Milner's book:

\begin{alltt}
STRONG_UNIQUE_SOLUTION:
\HOLthm{UniqueSolutions.STRONG_UNIQUE_SOLUTION}
\end{alltt}

\begin{alltt}
WEAK_UNIQUE_SOLUTION:
\HOLthm{UniqueSolutions.WEAK_UNIQUE_SOLUTION}
\end{alltt}

\begin{alltt}
OBS_UNIQUE_SOLUTION:
\HOLthm{UniqueSolutions.OBS_UNIQUE_SOLUTION}
\end{alltt}

\subsection{Unique solution of contractions}

The major difficulties in formalizing Sangiorgi's unique solution of
contractions theorem is to prove its main lemma (c.f. Lemma 3.9 of
main paper), in which the length of weak transitions are used for
induction. Introducing a special vesion of weak transition relation
with length would be an easier choice, but we have chosen to use trace
instead, so that in the future it's possible to extend the work with
trace equivalence included.

A trace is represented by the beginning and ending CCS processes, plus
a list of action it passes. Insteading of defining it directly, we
have first defined a new concept called Reflexive Transitive Closure with a
List (LRTC):
\begin{alltt}
\HOLthm{Trace.LRTC_DEF}
\end{alltt}
For any labelled translation relation $R$, \HOLtm{LRTC R} builds a new
relation accumulating all labels in the middle. Then the trace of CCS processes can be
defined by simply combining LRTC with the (strong) CCS transition
relation:
\begin{alltt}
\HOLthm[def]{Trace.TRACE_def}
\end{alltt}

If there's at most one visible action (label) in the list of actions of a trace,
then the trace is also a weak transition. We divided this observation
into two cases: no label and unique label. The definition of ``no
label'' in an action list is easy and clear:
\begin{alltt}
\HOLthm{Trace.NO_LABEL_def}
\end{alltt}
while the definition of ``unique label'' can be done in many ways, in
which we have chosen to use the version learnt from Robert Beers in
a private discussion which prevented counting or filtering in the list:
\begin{alltt}
\HOLthm{Trace.UNIQUE_LABEL_def}
\end{alltt}
It says, a label is unique in an action list iff it there's no other
labels in the rest part of the list.

The final relationship between traces and weak transitions is stated
and proved in the following lemma:
\begin{alltt}
WEAK_TRANS_AND_TRACE:
\HOLthm{Trace.WEAK_TRANS_AND_TRACE}
\end{alltt}
(A weak transition $E\overset{u}{\rightarrow}E'$ is a trace with non
empty action list: 1) without any visible label, if $u = \tau$, or 2)
$u$ is the unique label in the list, if $u \neq \tau$.)

To finish the proof of Lemma 3.9 in Sangiorgi's paper, we used above
lemma to convert weak transitions to traces, which either keep its
length or become shorter after passing weak bisimilations, then we
used above lemma again to convert the traces back to weak transitions.

The proof of the final unique solution of contractions theorem is just
a literal transition of its informal proofs: (noticed that the weakly
guarded context is the version without direct sums)
\begin{alltt}
\HOLthm{UniqueSolutions.UNIQUE_SOLUTION_OF_CONTRACTIONS}
\end{alltt}

\subsection{Unique solution of rooted contractions}

The proof of Unique solution of rooted contractions theorem is the
same proof steps of Unique solution of contractions theorem plus the
application of \texttt{OBS_CONGR_BY_WEAK_BISIM} at the
beginning.\footnote{In the thesis work, the conclusion of this theorem
is weak bisimilarity, and the proof is exactly the same as Unique
solution of contractions theorem. Now we got a stronger conclusion
using observational congruence, and the previous version becomes a
trivial collorary of the current version.} The
two proofs are quite similar, mostly because the only property we need
from (rooted) contraction is its precongruence. Once we have proved
the precongruence of rooted contracion, we can naturally use the
normal version of weakly guarded expressions with direct sums included.

\begin{alltt}
UNIQUE_SOLUTION_OF_ROOTED_CONTRACTIONS:
\HOLthm{UniqueSolutions.UNIQUE_SOLUTION_OF_ROOTED_CONTRACTIONS}
\end{alltt}

